{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLURM resource limits\n",
    "\n",
    "SLURM provides a hierarchy of jobs, steps and tasks. For each of these we can specify a set of resources to be used (nodes, CPUs, RAM).\n",
    "\n",
    "- How are jobs, job steps, step tasks scheduled across nodes?\n",
    "- How does SLURM use [Control Groups](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/ch01) to enforce resource limits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The task script\n",
    "This script will run as a task in each step. It simply logs information about SLURM resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting limits.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile limits.py\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "slurm = {\n",
    "    k[len('SLURM_'):]: v \n",
    "    for k, v in os.environ.items() \n",
    "    if k.startswith('SLURM_')\n",
    "}\n",
    "\n",
    "# Job info (printed by task 0 in step 0)\n",
    "if int(slurm['STEP_ID']) == 0 and int(slurm['PROCID']) == 0:\n",
    "    print(f\"Job {slurm['JOB_ID']}\")\n",
    "    print(\n",
    "        f\"  Submit host: {slurm['SUBMIT_HOST']}\",\n",
    "        f\"  Nodes      : {slurm['JOB_NODELIST']}\",\n",
    "        f\"  Num nodes  : {slurm['JOB_NUM_NODES']}\",\n",
    "        sep='\\n',\n",
    "        end='\\n\\n',\n",
    "    )\n",
    "    \n",
    "# Step info (printed by task 0 in each step)\n",
    "if int(slurm['PROCID']) == 0:\n",
    "    print(f\"Step {slurm['STEP_ID']}\")\n",
    "    print(\n",
    "        f\"  Nodes      : {slurm['STEP_NODELIST']}\",\n",
    "        f\"  Num nodes  : {slurm['STEP_NUM_NODES']}\",\n",
    "        f\"  Num tasks  : {slurm['STEP_NUM_TASKS']}\",\n",
    "        sep='\\n',\n",
    "        end='\\n\\n',\n",
    "    )\n",
    "    \n",
    "# Sleep to avoid overlaps in the log file\n",
    "time.sleep(int(slurm['PROCID']))\n",
    "\n",
    "# Get cgroup of this process\n",
    "# E.g. /slurm/uid_012345/job_001122/step_0/task_0\n",
    "with open(f'/proc/{os.getpid()}/cgroup') as f:\n",
    "#     cgroup = next(l.strip() for l in f if ':memory' in l).split(':')[2]\n",
    "    for l in f:\n",
    "        if ':memory' in l:\n",
    "            cgroup = l.strip().split(':')[2]    \n",
    "            *_, uid, job, step, task = cgroup.split('/')\n",
    "            uid = int(uid[len('uid_'):])\n",
    "            job = int(job[len('job_'):])\n",
    "            step = int(step[len('step_'):])\n",
    "            task = int(task[len('task_'):])\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError('Unable to parse cgroup info')\n",
    "\n",
    "# CPU quota of all tasks in this step\n",
    "# https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpuacct\n",
    "cpu_shares_tot = 0\n",
    "for p in glob.glob(f'/sys/fs/cgroup/cpu,cpuacct/slurm/uid_{uid}/job_{job}/step_{step}/task_*/cpu.shares'):\n",
    "    with open(p) as f:\n",
    "        cpu_shares_tot += int(f.readline())\n",
    "            \n",
    "# CPU quota of this task (as a fraction of the step quota)\n",
    "with open(f'/sys/fs/cgroup/cpu,cpuacct/slurm/uid_{uid}/job_{job}/step_{step}/task_{task}/cpu.shares') as f:\n",
    "    cpu_shares_task = int(f.readline())\n",
    "    \n",
    "# CPU cores bound to this step (shared among tasks)\n",
    "# https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpuset\n",
    "with open(f'/sys/fs/cgroup/cpuset/slurm/uid_{uid}/job_{job}/step_{step}/cpuset.cpus') as f:\n",
    "    cpu_cores = f.readline().strip()\n",
    "    \n",
    "# RAM \n",
    "# Soft/hard limits in bytes for this step/task\n",
    "# https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-memory\n",
    "with open(f'/sys/fs/cgroup/memory/slurm/uid_{uid}/job_{job}/step_{step}/memory.limit_in_bytes') as f:\n",
    "    mem_step_hard = float(f.readline())\n",
    "with open(f'/sys/fs/cgroup/memory/slurm/uid_{uid}/job_{job}/step_{step}/memory.soft_limit_in_bytes') as f:\n",
    "    mem_step_soft = float(f.readline())\n",
    "with open(f'/sys/fs/cgroup/memory/slurm/uid_{uid}/job_{job}/step_{step}/task_{task}/memory.limit_in_bytes') as f:\n",
    "    mem_task_hard = float(f.readline())\n",
    "with open(f'/sys/fs/cgroup/memory/slurm/uid_{uid}/job_{job}/step_{step}/task_{task}/memory.soft_limit_in_bytes') as f:\n",
    "    mem_task_soft = float(f.readline())\n",
    "    \n",
    "print(\n",
    "    f\"Task {slurm['PROCID']}\",\n",
    "    f\"  Hostname: {os.environ['SLURMD_NODENAME']}\",\n",
    "\n",
    "    # process ID of the task being started\n",
    "    f\"  Task PID: {slurm['TASK_PID']:<6}\",\n",
    "    \n",
    "    # step-wise task ID, i.e. MPI rank\n",
    "    f\"  Task id : {slurm['PROCID']:<6}\",\n",
    "    \n",
    "    # node local task ID for the process within this step\n",
    "    f\"  Local id: {slurm['LOCALID']:<6}\",\n",
    "    \n",
    "    f\"  Task control group : {cgroup}\",\n",
    "    \n",
    "    # CPU cores shared among the tasks in this step on this machine\n",
    "    f\"  CPU cores  per step: {cpu_cores:<10}\",\n",
    "    \n",
    "    # Percentage of the above cores that the task should use\n",
    "    f\"  CPU shares per task: {cpu_shares_task/cpu_shares_tot:<10.2%}\",\n",
    "    f\"  RAM limits per step: {mem_step_soft / 2**30:.2f} GB (hard {mem_step_hard / 2**30:.2f} GB)\",\n",
    "    f\"  RAM limits per task: {mem_task_soft / 2**30:.2f} GB (hard {mem_task_hard / 2**30:.2f} GB)\",\n",
    "    sep='\\n',\n",
    "    end='\\n\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Srun examples\n",
    "\n",
    "Running `srun` from a normal shell creates a job with a single step.\n",
    "\n",
    "A step can have multiple tasks:\n",
    "- All tasks are launched with the same script and parameters\n",
    "- Each task gets a unique task id (MPI rank)\n",
    "- The tasks can be run on a single node or span across multiple nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic single-task example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 125493\n",
      "  Submit host: moria\n",
      "  Nodes      : smaug\n",
      "  Num nodes  : 1\n",
      "\n",
      "Step 0\n",
      "  Nodes      : smaug\n",
      "  Num nodes  : 1\n",
      "  Num tasks  : 1\n",
      "\n",
      "Task 0\n",
      "  Hostname: smaug\n",
      "  Task PID: 30193 \n",
      "  Task id : 0     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125493/step_0/task_0\n",
      "  CPU cores  per step: 38,78     \n",
      "  CPU shares per task: 100.00%   \n",
      "  RAM limits per step: 1.95 GB (hard 1.95 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! srun --ntasks 1 python3 limits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two tasks on the same node\n",
    "\n",
    "Since the tasks execute on the same node, SLURM creates a single step cgroup and assigns 4 cores to it.\n",
    "\n",
    "The step has two childred tasks, each of which is limited to using 50% of the step cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 125494\n",
      "  Submit host: moria\n",
      "  Nodes      : smaug\n",
      "  Num nodes  : 1\n",
      "\n",
      "Step 0\n",
      "  Nodes      : smaug\n",
      "  Num nodes  : 1\n",
      "  Num tasks  : 2\n",
      "\n",
      "Task 0\n",
      "  Hostname: smaug\n",
      "  Task PID: 30228 \n",
      "  Task id : 0     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125494/step_0/task_0\n",
      "  CPU cores  per step: 38-39,78-79\n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 3.91 GB (hard 3.91 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 1\n",
      "  Hostname: smaug\n",
      "  Task PID: 30229 \n",
      "  Task id : 1     \n",
      "  Local id: 1     \n",
      "  Task control group : /slurm/uid_1295800031/job_125494/step_0/task_1\n",
      "  CPU cores  per step: 38-39,78-79\n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 3.91 GB (hard 3.91 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! srun --nodes 1 --ntasks 2 --cpus-per-task 2 python3 limits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two tasks, but on two different nodes\n",
    "\n",
    "Since the tasks execute on two separate nodes, SLURM creates a step cgroup on each machine and assigns 2 cores to each step.\n",
    "\n",
    "Each step has a single child task that gets to use 100% of the step cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 125495\n",
      "  Submit host: moria\n",
      "  Nodes      : balrog,belegost\n",
      "  Num nodes  : 2\n",
      "\n",
      "Step 0\n",
      "  Nodes      : balrog,belegost\n",
      "  Num nodes  : 2\n",
      "  Num tasks  : 2\n",
      "\n",
      "Task 0\n",
      "  Hostname: balrog\n",
      "  Task PID: 27904 \n",
      "  Task id : 0     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125495/step_0/task_0\n",
      "  CPU cores  per step: 37,77     \n",
      "  CPU shares per task: 100.00%   \n",
      "  RAM limits per step: 1.95 GB (hard 1.95 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 1\n",
      "  Hostname: belegost\n",
      "  Task PID: 13103 \n",
      "  Task id : 1     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125495/step_0/task_1\n",
      "  CPU cores  per step: 22,46     \n",
      "  CPU shares per task: 100.00%   \n",
      "  RAM limits per step: 1.95 GB (hard 1.95 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! srun --nodes 2 --ntasks 2 --cpus-per-task 2 python3 limits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three tasks across 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 125496\n",
      "  Submit host: moria\n",
      "  Nodes      : gondor,khazadum\n",
      "  Num nodes  : 2\n",
      "\n",
      "Step 0\n",
      "  Nodes      : gondor,khazadum\n",
      "  Num nodes  : 2\n",
      "  Num tasks  : 3\n",
      "\n",
      "Task 0\n",
      "  Hostname: gondor\n",
      "  Task PID: 609   \n",
      "  Task id : 0     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125496/step_0/task_0\n",
      "  CPU cores  per step: 18-19,38-39\n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 3.91 GB (hard 3.91 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 1\n",
      "  Hostname: gondor\n",
      "  Task PID: 610   \n",
      "  Task id : 1     \n",
      "  Local id: 1     \n",
      "  Task control group : /slurm/uid_1295800031/job_125496/step_0/task_1\n",
      "  CPU cores  per step: 18-19,38-39\n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 3.91 GB (hard 3.91 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 2\n",
      "  Hostname: khazadum\n",
      "  Task PID: 4128  \n",
      "  Task id : 2     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125496/step_0/task_2\n",
      "  CPU cores  per step: 4,28      \n",
      "  CPU shares per task: 100.00%   \n",
      "  RAM limits per step: 1.95 GB (hard 1.95 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! srun --nodes 2 --ntasks 3 --cpus-per-task 2 python3 limits.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sbatch example\n",
    "\n",
    "- `sbatch` allows to create jobs with multiple steps.\n",
    "- Steps are created using `srun` from within the `sbatch` script.\n",
    "- A pool of nodes is allocated to the job, then the individual steps can use nodes from this pool.\n",
    "\n",
    "Example:\n",
    "- 2 nodes\n",
    "- step 0 with 1 task\n",
    "- step 1 with 2 task\n",
    "- step 2 with 4 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting limits.sbatch\n"
     ]
    }
   ],
   "source": [
    "%%writefile limits.sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --output limits.out\n",
    "#SBATCH --nodes  2\n",
    "\n",
    "srun --nodes 1 --ntasks 1 python3 limits.py\n",
    "sleep 2\n",
    "srun --nodes 2 --ntasks 2 python3 limits.py\n",
    "sleep 2\n",
    "srun --nodes 2 --ntasks 4 --ntasks-per-node 2 --cpus-per-task 1 --mem-per-cpu 256M python3 limits.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    JobID  AllocCPUS    Elapsed      State ExitCode        NodeList \n",
      "------------------------- ---------- ---------- ---------- -------- --------------- \n",
      "125497                             4   00:00:11  COMPLETED      0:0 balrog,belegost \n",
      "125497.batch                       2   00:00:11  COMPLETED      0:0          balrog \n",
      "125497.0                           1   00:00:00  COMPLETED      0:0          balrog \n",
      "125497.1                           2   00:00:02  COMPLETED      0:0 balrog,belegost \n",
      "125497.2                           4   00:00:04  COMPLETED      0:0 balrog,belegost \n",
      "\n",
      "Job 125497\n",
      "  Submit host: balrog.csc.kth.se\n",
      "  Nodes      : balrog,belegost\n",
      "  Num nodes  : 2\n",
      "\n",
      "Step 0\n",
      "  Nodes      : balrog\n",
      "  Num nodes  : 1\n",
      "  Num tasks  : 1\n",
      "\n",
      "Task 0\n",
      "  Hostname: balrog\n",
      "  Task PID: 27977 \n",
      "  Task id : 0     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125497/step_0/task_0\n",
      "  CPU cores  per step: 37,77     \n",
      "  CPU shares per task: 100.00%   \n",
      "  RAM limits per step: 1.95 GB (hard 1.95 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Step 1\n",
      "  Nodes      : balrog,belegost\n",
      "  Num nodes  : 2\n",
      "  Num tasks  : 2\n",
      "\n",
      "Task 0\n",
      "  Hostname: balrog\n",
      "  Task PID: 28022 \n",
      "  Task id : 0     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125497/step_1/task_0\n",
      "  CPU cores  per step: 37,77     \n",
      "  CPU shares per task: 100.00%   \n",
      "  RAM limits per step: 1.95 GB (hard 1.95 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 1\n",
      "  Hostname: belegost\n",
      "  Task PID: 13242 \n",
      "  Task id : 1     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125497/step_1/task_1\n",
      "  CPU cores  per step: 22,46     \n",
      "  CPU shares per task: 100.00%   \n",
      "  RAM limits per step: 1.95 GB (hard 1.95 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Step 2\n",
      "  Nodes      : balrog,belegost\n",
      "  Num nodes  : 2\n",
      "  Num tasks  : 4\n",
      "\n",
      "Task 0\n",
      "  Hostname: balrog\n",
      "  Task PID: 28070 \n",
      "  Task id : 0     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125497/step_2/task_0\n",
      "  CPU cores  per step: 37,77     \n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 0.50 GB (hard 0.50 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 1\n",
      "  Hostname: balrog\n",
      "  Task PID: 28071 \n",
      "  Task id : 1     \n",
      "  Local id: 1     \n",
      "  Task control group : /slurm/uid_1295800031/job_125497/step_2/task_1\n",
      "  CPU cores  per step: 37,77     \n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 0.50 GB (hard 0.50 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 2\n",
      "  Hostname: belegost\n",
      "  Task PID: 13283 \n",
      "  Task id : 2     \n",
      "  Local id: 0     \n",
      "  Task control group : /slurm/uid_1295800031/job_125497/step_2/task_2\n",
      "  CPU cores  per step: 22,46     \n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 0.50 GB (hard 0.50 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n",
      "Task 3\n",
      "  Hostname: belegost\n",
      "  Task PID: 13284 \n",
      "  Task id : 3     \n",
      "  Local id: 1     \n",
      "  Task control group : /slurm/uid_1295800031/job_125497/step_2/task_3\n",
      "  CPU cores  per step: 22,46     \n",
      "  CPU shares per task: 50.00%    \n",
      "  RAM limits per step: 0.50 GB (hard 0.50 GB)\n",
      "  RAM limits per task: 8589934592.00 GB (hard 8589934592.00 GB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -f limits.out\n",
    "\n",
    "JOBID=\"$(sbatch --parsable limits.sbatch)\"\n",
    "while [ -n \"$(squeue | grep ${JOBID})\" ]; do sleep 1; done\n",
    "sacct --job $JOBID --format JobID%-25,AllocCPUS,Elapsed,State,ExitCode,NodeList\n",
    "echo \"\"\n",
    "\n",
    "cat limits.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
